\chapter{Background}
\label{ch:temporal_dynamics}

Time is undoubtedly one of the most mysterious concepts.  We may learn to `tell time', but our understanding is so natural, and empirically enforced that we never need to explicitly be be told or reminded of its basic qualities.  However, when analyzed more critically, or scientifically, time is paradoxical and its nature, construction and impact continues to occupy the minds of great thinkers.

Two critical assumptions are made by automated reasoning methods. First, a underlying characteristic of unidirectionality, that defines time as an infinite, forward moving trajectory.  Secondly, that information about the past can be propagated along this temporal trajectory, or a quality of persistence.  These two assumptions are perhaps the most basic, and are consistent with an enormous amount of evidence that can be observed in both our internal and external environments.

Methods for modeling temporal data vary most dramatically not in a rejection of these basic assumptions, but rather the simplifying assumptions that facilitate analysis and are used to structure and summarize raw time series values.  Many are known to be false, for example representing a temporal process by modeling one snapshot, but are either required for any analysis at all, or present a limited effect on results.

\section{What are the Questions to Ask?}
When little prior knowledge about group structure is known and a collection of observations is too large for a human to peruse, unsupervised-learning algorithms, also known as unsupervised classification, can be useful.  To this end, we have developed a clustering method for longitudinal patient data that more easily extends to new data sets, and in contrast to discrete time approaches, is more appropriate for the preprocessing and exploratory analysis of incomplete, irregular observation sequences that are common to patient data found in electronic health records.

Clustering is a pervasive and natural human activity that us used for a variety of tasks. Typically, we use it to group similar objects together so that we can assign characteristics that are useful for their definition.   At the minimal level, automated clustering can be viewed at preprocessing with the goal of improving the performance of a system.  For example, in a collection of patients with a potentially lethal disease only diagnosed using an invasive procedure, clustering can help to determine those patients of minimal risk.  A consequent processing step can focus on the set of patients more likely to develop a terminal condition.

In the context of exploratory data analysis, clustering techniques are applied to data with the aim of discovering underlying patterns that can be used to generate new hypotheses for more targeted data analysis.  However, the interpretation of cluster goodness can be problematic.  Even with a gold standard for evaluation performance, it is important to note that within a specific domain of application, there can be opposing views that are not resolvable.  For example, in biology there can be very diverse views on the classification of the same organism~\cite{pmid20500846,pmid23209778}.

\section{Time as Critical Context}
Sequential data can exist in the form of word order in a sentence, or it can exist in a more explicit temporal form that is generated by a process.  This work focuses specifically on temporal data, which are a special form of sequential data that are typically measured uniformly, and often referred to as `time series', but may reflect variable time granularities and other irregularities that required a modeling process to account for more uncertainly.

\subsection{The Flow of Time}
The philosophy of space and time and whether it exist independently from each other, is a question of the most importance, but beyond the scope of this thesis.  For the purpose of this work, we assume that time is a unidirectional flow and continuous in nature.  We also assume that the dynamic processes can be represented at specific instances using a temporal marker.  For this reason, we can measure the change of a process with respect to time by observing the differences between any two time markers, or points, on a temporal trajectory.

In this work, we do not attempt to theorize about the underlying nature of time.  However, we do make a case for a more accurate representation to model temporal dynamics that have direct relevance to important data analysis problems.  That is, for processes monitored at fixed intervals, the discretization of time into a vector of uniform length fragments, is an appropriate modeling assumption.  Although no one would argue that time is discrete, when observations are collected in high-frequency settings, or continually monitored at regular intervals it presents benefits.  However, this is not appropriate in the case in data sources that evolve in continuous time, subject to variable sampling schemes and incomplete.


\section{Semiparametric Temporal Clustering}
Regardless of the temporal mining task, the first step of an algorithm is to transform, or abstract, the raw data into a more concise representation, preserving as much of the information contained in the original sequence as possible.  \emph{Semiparametric temporal clustering} makes useful parametric assumptions to approximate temporal data and regularize sequences for input to a clustering step.  The temporal abstractions, abstractions of the raw time-series, function as input to a nonparametric clustering algorithm, which seeking to reveal underlying structure and be more agnostic about properties of the resulting clusters.

\begin{figure}[t]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{fig/semipoverview.jpg}}
\caption{An Overview of Semiparametric Clustering}
\label{semipoverview}
\end{center}
\vskip -0.2in
\end{figure}

Figure~\ref{semipoverview} shows an overview of the semiparametric temporal clustering framework. The first step entails temporal abstraction using a parametric model to transform a set of raw time series for $N$ observations, $X_1, X_1,...,X_N$, into a more manageable form for traditional multivariate clustering algorithms. It entails learning each patients model-specific parameters, $Q_1, Q_2, ..., Q_N$, from the time series observations.

The second step is nonparametric clustering. Spectral methods are typically used in the semiparametric framework, which requires determining the number of clusters, $k$, in advance. In this work, we extend the
clustering component to the nonparametric Bayesian setting, allowing for the number of clusters to be expressed as a function of the sample size.

\subsection{Modeling Chronic Disease Dynamics}
One specific case for which discretization of the temporal trajectory into regular intervals has been known to contribute to error, is that of longitudinal data derived from monitoring disease phenomena and is why there are fewer applications of discrete-time Markov models in medicine~\cite{Jackson2011}.  SInce observations are typically documented only during hospital or physician visits, resulting in irregular time intervals.  Also, a patient's measurement sequence be short or can span over many years and the nature of the observation scheme (e.g., fixed, random or self-selected) can be unclear.

Despite these challenges, health services researchers generally agree that electronic health record (EHR) data provides many opportunities for new knowledge discovery, and there is tremendous potential for value beyond meaningful use.  The temporal dimension of indicter data provides critical context for diagnosis and prognosis of many patients suffering from chronic diseases.

Historically, following a cohort of individuals entailed the design of customized measurement tools to monitoring patients for a research study and explicit checkpoints for data collection.  Now, the number of human data artifacts is increasing, and each new datum has the potentially help to provide further clinical insights.  Conventional methods for temporal mining are not designed to accommodate for the type of noise incompleteness, and other features that are associated with modeling from patient records.  To provide a better understanding of dynamic changes that can occur during the course of a patient's disease trajectory, this work examines new semi-parametric clustering methods for temporal data.

Currently, when exploratory analysis is performed in electronic health records (EHRs ) it does not consist of a automated examination of possibilities and potential structures.  Rather, a domain expert will typically use prior knowledge to reason about distinctions within a population, and carefully select a sample or sub-population that they suspect may result in significantly different clinical or other outcomes.  These prior assumptions guide targeted research questions, and are more likely to result in findings~\cite{Ioannidis05}

\section{Modeling Challenges}
\subsection{Selecting the `Right' Granularity}
\subsection{Sampling and Aligning Temporal Data}
