\subsection{Bayesian Networks}
Bayesian Networks (BNs) are a type of PGM that can be used to represent the key observable and latent variables of a system as \emph{nodes} in a graph and the probabilistic interactions between them as \emph{directed edges}.  In order to model a dynamic system where node values change dynamic Bayesian networks (DBNs) link $T$ template models, in this case BNs, with edges in the direction of time to define the conditional probability distribution for temporal transitions.

The graphical model formalism provides general algorithms for the calculation of marginal and conditional probabilities for a set of observations generated by various types of processes.  Also, they provide the flexibly for modeling complex problems.  Since each graph's semantics are separate from the algorithms that can be applied to the structures~\cite{koller} the algorithmic components can be reused more easily and have they have already demonstrated success for many types of learning tasks.


Bayesian Networks (BNs) are a type of PGM that can be used to represent the key observable and latent variables of a system as \emph{nodes} in a graph and the probabilistic interactions between them as \emph{directed edges}.  In order to model a dynamic system where node values change Dynamic Bayesian Networks (DBNs) link $T$ template models, in this case BNs, with edges in the direction of time to define the conditional probability distribution for temporal transitions. The graphical model formalism provides general algorithms for the calculation of marginal and conditional probabilities for a set of observations generated by various types of processes.  Also, they provide the flexibly for modeling complex problems, and each graph's semantics are separate from the algorithms that can be applied to the structures~\cite{koller}.  Since the algorithmic components can be reused more easily, and show good performance on very simple problem models, they have already demonstrated success for many types of supervised and unsupervised learning in across seemingly unrelated domains.

Our work focuses on modeling the temporal aspect of data, more specifically, data in the form of time series, and for that reason we limit further discussion to the use of graphical models in this context.  PGMs that formalize temporal dynamics typically represent a time series of length $T$ as a collection of ordered points points corresponding with a specific model state $Q$ that can assume one of $M$ possible values so that for any $t$, $Q_{t} \in \{1,...,M\}$.  We begin with a set of definition that are key to understanding how to construct an informative but concise abstraction of a system's temporal dynamics in a graphical structure.

\begin{description}
  \item[State Space Models (SSM)]  A SSM is a model that assumes an underlying state, or set of states, that are associated with a temporal phenomena and generates observations over time.  SSMs requires the definition of state transition probabilities, $P(Q_{t} | Q_{t-1})$, indicating the probability from transiting from one state to any other, the observation probabilities, $P(Y_{t} | Q_{t})$, indicating the probability of an observation given the current state value, and the initial state probability distributions $\pi$.
  \item[Markov property]  The Markov property states that the conditional probability distribution of a future state $Q_{t+1}$ is conditionally independent of states $Q_{i}$, where $i<t$, given $Q_{t}$.  Or more simply, given full knowledge of the current state, the future and the past are independent.  In general, if a simple but informative state description for a dynamic process can be defined, the Markov assumption is generally a reasonable approximation of the dependencies in a distribution.  A system for which the Markov assumption holds is considered a Markovian system, and PGMs that  relax the independence assumption are considered semi-Markovian.
  \item[Hidden Markov Model (HMM)] HMMs are use when model states are latent but for which correlated indicator variables exist. For HMMs, $Q_{t}$ is represented by a single `hidden' discrete random variable.  Figure~\ref{hidden} shows a HMM with 3 hidden states $Q_{1},Q_{2},Q_{3}$ that can assume any of the $M$ possible values and are correlated with the set of observations, $O_{1},O_{2},O_{3}$, also known as a Markov chain.  Like states, the values of observations come from a pre-defined set.  For the purpose of inference, these probability tables are known, or can be learned with optimization technique such as the forward-backward algorithm.   A more detailed description of HMMs are provided by Rabiner~\cite{Rabiner89atutorial}.

For the random variables in the temporal model, given the values of the variables in the previous model state the distribution of trajectories can be defined as the product of the conditional distributions and calculated using the chain rule.  More formally:
$$P(Q_{T})=\prod_{t=1}^{T}P(Q_{0})P(Q_{t+1} | Q_{t})$$

    \begin{figure}
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,semithick]
\tikzstyle{every state}=[fill=blue!8,draw=black,thick,text=black,scale=1]


\node[state]         (A)              {$Q_{1}$};

\node[state]         (B) [right of=A] {$Q_{2}$};
\node[state]         (C) [right of=B] {$Q_{3}$};
\node[state,fill=blue!32]         (D) [below of=A] {$O_{1}$};
\node[state,fill=blue!32]          (E) [right of=D] {$O_{2}$};
\node[state,fill=blue!32]          (F) [right of=E] {$O_{3}$};

\path (A) edge  [right] node[below] {} (B);
\path (B) edge  [right] node[below] {} (C);
\path (A) edge  [below] node[below] {} (D);
\path (B) edge  [below] node[below] {} (E);
\path (C) edge  [below] node[below] {} (F);

\end{tikzpicture}
\end{center}
\caption{A hidden Markov model for time series of length $T=3$, where at any time $t \in \{1,...,T\}$ the value of a hidden model state is $Q_{t}$ and $O_{t}$ is the corresponding observation.}
\label{hidden}
\end{figure}
    %$$P(X^{0:T})=P(X^{0})\prod_{t=0}^{T-1} P(X^{t+1} | X^{0:t})$
  \item[Bayesian Networks (BNs)] A Bayesian Network, or Bayes net, is a probabilistic model that is represented as a DAG, where nodes represent random variables of interest, edges represent informational or causal dependencies among variables, and each node is conditionally independent of its non-descendants given the parents. Since they allow for a richer structural versatility, Bayes nets allow for more complex models to be represented.

      Let $X_i$ be a node in the BN, $X$, over the variables $X_{1},...,X_{n}$ and let Pa($X_i$) be the parents of $X_i$.  Based on the independence assumptions, we can define the joint probability distribution $P(X)$ using the chain rule for BNs as follows:
      $$P(X_{1},...,X_{n})= \prod_{i=1}^{n}P(X_i)|Pa(X_i)$$

    \item[Dynamic Bayesian Networks (DBNs)] For modeling time series, we can construct a DBN out of a BN, which functions as a \emph{template}, by instantiating the set of template variables for each time slice.  The set of template variables are repeated for each point in series and directed edges are added between time slices in the direction of time to reflect the template variables that interface between slices.  In a two-slice temporal Bayes net (2-TBN) edges are of two main types:  \emph{inter-time-slice edges} that interface between time slices or \emph{intra-time-slice-edges} that reflect the conditional dependencies among variables and within a single time slice.  Figure~\ref{patientdbn} shows a DBN with three instantiations of template variables.  Adjacent sets of template variables constitute a 2-TBN.
        \end{description}
        
\subsection{Markov Processes}
Markovian models are based on the underlying assumption that the future state of a system, $Q_{t+1}$, is independent of all past states, given the current state $Q_{t}$.  Hidden Markov models (HMMs) are useful for representing phenomena that care not directly observed, but for which a correlated variable can provide sufficient information to make inferences about the latent or \emph{hidden} state's value.

PGMs that formalize temporal dynamics typically represent a time series of length $T$ as a collection of ordered points points corresponding with a specific model state $Q$ that can assume one of $M$ possible values so that for any $t$, $Q_{t} \in \{1,...,M\}$.  One simplifying assumption for sequential data that has been widely applied for modeling many different types of sequential processes is the Markov assumption.  The Markov property states that the conditional probability distribution of a future state $Q_{t+1}$ is conditionally independent of states $Q_{i}$, where $i<t$, given $Q_{t}$.  Or more simply, given full knowledge of the current state, the future and the past are independent.  In general, if a simple but informative state description for a dynamic process can be defined, the Markov assumption is generally a reasonable approximation of the dependencies in a distribution.

\subsubsection{Hidden Markov Models}
HMMs are defined by a triple, $\{ A, B, \pi \}$ over a set of discrete states and distinct observations.  The matrix $A$ represents the state transitions, or the probability of moving from the current state, $q_{i}$, to the next state, $q_{i+1}$. The model parameter $B$ indicates the probability of an observation value for each $q\in Q$.

Although discrete-time models are suitable in many cases, there are two key limitations that have been noted (Saria 2007) and are directly relevant to the type of data typically found in provider databases.  First, if the underlying health related phenomena that is being modeled progresses in individuals at different rates, the smallest granularity must be used to express time steps for the entire system.  Second, when data is unavailable, intervening time slices must still be represented.


\subsubsection{Representation}
      We can view a HMM as a the simplest type of non-trivial DBN.  Alternative representation of DBNs extend the basic HMM model in that they are able to capture richer semantic information than HMMs, allowing temporal phenomena to be modeled more accurately.  For example, in a time slice DBNs allow for multiple model states; i.e., a DBN time slice $Z_{t}^{(i)}$ permits a set of $n$ states where $i \in \{1,...,n\}$.  Also, it permits a set of corresponding observations for $i$ that can assume discrete or continuous values.  Some other advantages over HMMs for modeling real-world phenomena is that they can relax the Markovian assumption to model semi-Markovian dynamics, and can be used to create multi-layer structures that have the potential to reflect local interactions among layers.

      The corresponding conditional distribution for the transition model of a 2-TBN makes two simplifying assumptions: (1) a dynamic system over the template variables $X$ satisfy the Markovian system and (2) a Markovian dynamic system is time invariant, or that $P(X_{t+1}|X)$ is the same for all values of $t$.  Since time is an infinite trajectory, these assumptions allow for modeling the state transition model more compactly.

      Let $Z$ be a set of $n$ persistent template variables that transfer temporal information in a 2-TBN.  We can represent the conditional distribution as:
      $$P(Z_{t+1} | Z_{t})= \prod_{i=1}^{n}P(Z_{t+1}^{(i)}|Pa(Z_{t+1}^{(i)}))$$
      \noindent For example, Figure~\ref{patientdbn} is a simple DBN model for monitoring a patient's disease acuity.  The variables are defined as : $A$=Access to care, $C$=Compliance, $D$=Disease Management, $R$=comoRbidities.  The model's structure conveys problem knowledge such as the level of compliance with treatment (C) is conditionally dependent on access to care (A).  Assuming all nodes are persistent, we can represent the conditional distribution based on the formula:
      $$P(Z_{t+1}|Z_{t})=P(Z_{t+1}^{A}|Z_{t}^{A})P(Z_{t+1}^{C}|Z_{t+1}^{A}Z_{t}^{C})P(Z_{t+1}^{D}|Z_{t+1}^{C}Z_{t}^{D}Z_{t+1}^{R})P(Z_{t+1}^{R}|Z_{t}^{R})$$
\begin{figure}[h]
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,semithick]
\tikzstyle{every state}=[fill=blue!22,draw=black,thick,text=black,scale=1]

\node[state]         (A1)              {$Z_{1}^{A}$};
\node[state]         (C1) [below of=A1] {$Z_{1}^{C}$};
\node[state]         (R1) [right of=C1] {$Z_{1}^{R}$};
\node[state]         (D1) [below of=C1] {$Z_{1}^{D}$};


\node[state]         (C2) [right of=R1] {$Z_{2}^{C}$};
\node[state]         (A2) [above of=C2] {$Z_{2}^{A}$};
\node[state]         (R2) [right of=C2] {$Z_{2}^{R}$};
\node[state]         (D2) [below of=C2] {$Z_{2}^{D}$};

\node[state]         (C3) [right of=R2] {$Z_{3}^{C}$};
\node[state]         (A3) [above of=C3] {$Z_{3}^{A}$};
\node[state]         (R3) [right of=C3] {$Z_{3}^{R}$};
\node[state]         (D3) [below of=C3] {$Z_{3}^{D}$};

%\path (A) edge  [right] node[below] {} (B);
%\path (B) edge  [right] node[below] {} (C);
%\path (D) edge  [right] node[right] {} (B);
%\path (E) edge  [right] node[right] {} (C);

\path (R1) edge  [right] node[below] {} (D1);
\path (A1) edge  [right] node[below] {} (C1);
\path (C1) edge  [left] node[right] {} (D1);
\path (R2) edge  [right] node[below] {} (D2);
\path (A2) edge  [right] node[below] {} (C2);
\path (C2) edge  [left] node[right] {} (D2);
\path (R3) edge  [right] node[below] {} (D3);
\path (A3) edge  [right] node[below] {} (C3);
\path (C3) edge  [left] node[right] {} (D3);

\draw[dotted, ->] (5.5,-1) -- (6.5,-1) node [above]{$\Delta t$};
\draw[dotted, ->] (1.5,-1) -- (2.5,-1) node [above]{$\Delta t$};
\end{tikzpicture}
\end{center}
\caption{Dynamic Bayesian network (DBN), T=3}
\label{patientdbn}
\end{figure}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=.85\linewidth]{fig/patientdbn.png}
%\caption{Dynamic Bayesian network (DBN)}
%\label{patientdbn}
%\end{figure}